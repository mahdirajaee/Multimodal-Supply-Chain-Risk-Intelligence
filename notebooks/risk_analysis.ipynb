{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecd9e7d",
   "metadata": {},
   "source": [
    "# Supply Chain Risk Analysis\n",
    "\n",
    "Comprehensive analysis and visualization of multimodal supply chain risk predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd209bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from data.data_manager import DataManager\n",
    "from models.model_manager import ModelManager\n",
    "from fusion.risk_fusion import RiskFusionEngine\n",
    "from api.predictor import RiskPredictor\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc16575",
   "metadata": {},
   "source": [
    "## Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51246485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_performance_data():\n",
    "    models = ['Satellite', 'Sentiment', 'Weather', 'Economic', 'News']\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    data = []\n",
    "    \n",
    "    for model in models:\n",
    "        for metric in metrics:\n",
    "            base_score = np.random.uniform(0.75, 0.95)\n",
    "            data.append({\n",
    "                'Model': model,\n",
    "                'Metric': metric,\n",
    "                'Score': base_score\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "performance_df = generate_synthetic_performance_data()\n",
    "\n",
    "fig = px.bar(performance_df, x='Model', y='Score', color='Metric',\n",
    "             title='Individual Model Performance Metrics',\n",
    "             barmode='group')\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23a7e1",
   "metadata": {},
   "source": [
    "## Risk Score Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_risk_predictions(n_samples=1000):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    risk_types = ['Overall', 'Operational', 'Financial', 'Reputational']\n",
    "    dates = pd.date_range(start='2024-01-01', periods=n_samples, freq='H')\n",
    "    \n",
    "    data = []\n",
    "    for i, date in enumerate(dates):\n",
    "        base_risk = 0.3 + 0.2 * np.sin(i * 0.01) + np.random.normal(0, 0.1)\n",
    "        data.append({\n",
    "            'timestamp': date,\n",
    "            'Overall': np.clip(base_risk, 0, 1),\n",
    "            'Operational': np.clip(base_risk * 1.2, 0, 1),\n",
    "            'Financial': np.clip(base_risk * 0.8, 0, 1),\n",
    "            'Reputational': np.clip(base_risk * 0.6, 0, 1)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "risk_df = simulate_risk_predictions()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Overall Risk Distribution', 'Operational Risk Distribution',\n",
    "                   'Financial Risk Distribution', 'Reputational Risk Distribution']\n",
    ")\n",
    "\n",
    "risk_types = ['Overall', 'Operational', 'Financial', 'Reputational']\n",
    "positions = [(1,1), (1,2), (2,1), (2,2)]\n",
    "\n",
    "for risk_type, (row, col) in zip(risk_types, positions):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=risk_df[risk_type], name=risk_type, nbinsx=30),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Risk Score Distributions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145cb88",
   "metadata": {},
   "source": [
    "## Temporal Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for risk_type in risk_types:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=risk_df['timestamp'],\n",
    "        y=risk_df[risk_type],\n",
    "        mode='lines',\n",
    "        name=f'{risk_type} Risk',\n",
    "        line=dict(width=2)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Risk Score Evolution Over Time',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Risk Score',\n",
    "    height=500,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6b4ba",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_importance():\n",
    "    features = [\n",
    "        'Satellite Imagery Analysis',\n",
    "        'Social Media Sentiment',\n",
    "        'Weather Patterns',\n",
    "        'Economic Indicators',\n",
    "        'News Event Extraction',\n",
    "        'Transportation Routes',\n",
    "        'Supplier Stability',\n",
    "        'Geopolitical Events',\n",
    "        'Market Volatility',\n",
    "        'Port Congestion'\n",
    "    ]\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    importance_scores = np.random.uniform(0.1, 0.9, len(features))\n",
    "    importance_scores = importance_scores / importance_scores.sum()\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importance_scores\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "\n",
    "importance_df = generate_feature_importance()\n",
    "\n",
    "fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',\n",
    "             title='Feature Importance in Risk Prediction',\n",
    "             color='Importance', color_continuous_scale='viridis')\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e280b24",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7895ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = risk_df[risk_types].corr()\n",
    "\n",
    "fig = px.imshow(correlation_matrix, \n",
    "                text_auto=True, \n",
    "                aspect=\"auto\",\n",
    "                title=\"Risk Type Correlation Matrix\",\n",
    "                color_continuous_scale='RdBu_r')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f9802",
   "metadata": {},
   "source": [
    "## Real-time Prediction Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7dac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_risk_gauge(risk_score, title):\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode = \"gauge+number+delta\",\n",
    "        value = risk_score,\n",
    "        domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "        title = {'text': title},\n",
    "        delta = {'reference': 0.5},\n",
    "        gauge = {\n",
    "            'axis': {'range': [None, 1]},\n",
    "            'bar': {'color': \"darkblue\"},\n",
    "            'steps': [\n",
    "                {'range': [0, 0.3], 'color': \"lightgray\"},\n",
    "                {'range': [0.3, 0.7], 'color': \"gray\"},\n",
    "                {'range': [0.7, 1], 'color': \"red\"}],\n",
    "            'threshold': {\n",
    "                'line': {'color': \"red\", 'width': 4},\n",
    "                'thickness': 0.75,\n",
    "                'value': 0.8}\n",
    "        }\n",
    "    ))\n",
    "    return fig\n",
    "\n",
    "current_risk = np.random.uniform(0.3, 0.8)\n",
    "gauge_fig = create_risk_gauge(current_risk, \"Current Overall Risk\")\n",
    "gauge_fig.update_layout(height=400)\n",
    "gauge_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d3840",
   "metadata": {},
   "source": [
    "## Model Training Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_training_history():\n",
    "    epochs = range(1, 101)\n",
    "    models = ['Satellite', 'Sentiment', 'Weather', 'Economic', 'News']\n",
    "    \n",
    "    data = []\n",
    "    for model in models:\n",
    "        np.random.seed(hash(model) % 1000)\n",
    "        initial_loss = np.random.uniform(2.0, 4.0)\n",
    "        for epoch in epochs:\n",
    "            loss = initial_loss * np.exp(-epoch/30) + np.random.normal(0, 0.05)\n",
    "            data.append({\n",
    "                'Epoch': epoch,\n",
    "                'Model': model,\n",
    "                'Loss': max(loss, 0.1)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "training_df = simulate_training_history()\n",
    "\n",
    "fig = px.line(training_df, x='Epoch', y='Loss', color='Model',\n",
    "              title='Training Loss Curves for Individual Models',\n",
    "              log_y=True)\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
